{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474a4713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T13:18:38.452053Z",
     "iopub.status.busy": "2022-02-16T13:18:38.451477Z",
     "iopub.status.idle": "2022-02-16T13:21:14.388288Z",
     "shell.execute_reply": "2022-02-16T13:21:14.386993Z",
     "shell.execute_reply.started": "2022-02-16T13:18:38.451954Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from geospark.register import GeoSparkRegistrator\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import FloatType, IntegerType, LongType\n",
    "from pyspark.sql.window import Window\n",
    "from tqdm import tqdm\n",
    "\n",
    "config = yaml.load(open(r\"config/config.yaml\"), Loader=yaml.FullLoader)\n",
    "conf = SparkConf().setAll(config[\"sparkConf\"].items())\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"GKHDistribution\")\n",
    "    .config(conf=conf)\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "GeoSparkRegistrator.registerAll(spark)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from lib.distribution import *\n",
    "from lib.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb04ddb",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "727b9dfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T13:50:55.498307Z",
     "iopub.status.busy": "2022-02-16T13:50:55.497733Z",
     "iopub.status.idle": "2022-02-16T13:50:55.839861Z",
     "shell.execute_reply": "2022-02-16T13:50:55.837873Z",
     "shell.execute_reply.started": "2022-02-16T13:50:55.498242Z"
    }
   },
   "outputs": [],
   "source": [
    "# Features table and features\n",
    "categoricalFeatures = [\"houseguid\"]\n",
    "numericalFeatures = [\n",
    "    \"floor_count_max\",\n",
    "    \"quarters_count\",\n",
    "    \"entrance_count\",\n",
    "    \"area_total\",\n",
    "    \"parking_square\",\n",
    "    \"living_quarters_count\",\n",
    "]\n",
    "\n",
    "grid = spark.table(config[\"tableConf\"][\"gridBuffers\"])\n",
    "dataFeatures = (\n",
    "    spark.table(config[\"tableConf\"][\"gkh\"])\n",
    "    .dropDuplicates([\"houseguid\"])\n",
    "    .na.fill(0, numericalFeatures)\n",
    ")\n",
    "\n",
    "featuresGeometry = \"geometry\"\n",
    "gridID = \"gid\"\n",
    "gridGeometry = \"geom_wkt\"\n",
    "\n",
    "dbName = \"\"\n",
    "prefixName = \"\"\n",
    "\n",
    "# Dictionary tables: which cell buffer intersect which cell\n",
    "buffersDicts = {\n",
    "    \"\": None,\n",
    "    spark.table(f\"{dbName}.{prefixName}_grid_dict_buffer_1km\"): \"buffer_1km\",\n",
    "    spark.table(f\"{dbName}.{prefixName}_grid_dict_buffer_2km\"): \"buffer_2km\",\n",
    "    spark.table(f\"{dbName}.{prefixName}_grid_dict_buffer_3km\"): \"buffer_3km\",\n",
    "    spark.table(f\"{dbName}.{prefixName}_grid_dict_buffer_4km\"): \"buffer_4km\",\n",
    "    spark.table(f\"{dbName}.{prefixName}_grid_dict_buffer_5km\"): \"buffer_5km\",\n",
    "}\n",
    "\n",
    "# Tables for writing and their aliases\n",
    "tblAndAliases = {\n",
    "    f\"{dbName}.{prefixName}_grid_gkh_grid\": \"grid\",\n",
    "    f\"{dbName}.{prefixName}_grid_gkh_1km\": \"1km\",\n",
    "    f\"{dbName}.{prefixName}_grid_gkh_2km\": \"2km\",\n",
    "    f\"{dbName}.{prefixName}_grid_gkh_3km\": \"3km\",\n",
    "    f\"{dbName}.{prefixName}_grid_gkh_4km\": \"4km\",\n",
    "    f\"{dbName}.{prefixName}_grid_gkh_5km\": \"5km\"}\n",
    "\n",
    "toWriteTbls = list(tblAndAliases.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31444d2",
   "metadata": {},
   "source": [
    "## Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a2f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridDistrib = GridDistribution(\n",
    "    grid,\n",
    "    gridID,\n",
    "    gridGeometry,\n",
    "    dataFeatures,\n",
    "    featuresGeometry,\n",
    "    numericalFeatures,\n",
    "    categoricalFeatures,\n",
    ")\n",
    "\n",
    "# Intersection of features and grids\n",
    "featuresAndGrid = gridDistrib.featuresByGrid()\n",
    "\n",
    "for tblNumber, bufferTbl in enumerate(buffersDicts.keys()):\n",
    "    bufferData = bufferTbl\n",
    "    bufferColumn = buffersDicts[bufferTbl]\n",
    "\n",
    "    gridDistribGKH = gridDistrib.gridFeaturesAgg(\n",
    "        featuresAndGrid, bufferData, bufferColumn\n",
    "    )\n",
    "\n",
    "    saveTableOverwritePartition(gridDistribGKH, 50, [gridID], toWriteTbls[tblNumber])\n",
    "\n",
    "\n",
    "toWriteTbl = f\"{dbName}.{prefixName}_geo_grid_gkh\"\n",
    "\n",
    "GKHJoining = gridDistrib.joining(tblAndAliases)\n",
    "\n",
    "saveTableOverwritePartition(\n",
    "    GKHJoining, 135, [gridID], toWriteTbl,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c029aad",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import keplergl\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f17b2b",
   "metadata": {},
   "source": [
    "### Take only one region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "regionID = # insert your value\n",
    "featuresDF = spark.table(f\"{dbName}.{prefixName}_geo_grid_gkh\")\n",
    "gridLocal = grid.filter(col(\"region_id\") == regionID)\n",
    "\n",
    "featuresDF = (\n",
    "    featuresDF\n",
    "    .join(gridLocal, [f\"{gridID}\"], \"inner\")\n",
    "    .withColumnRenamed(f\"{gridGeometry}\", \"geometry\")\n",
    ")\n",
    "\n",
    "print(featuresDF.count())\n",
    "\n",
    "df = featuresDF.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403cd71e",
   "metadata": {},
   "source": [
    "### Transform to geopandas and add to map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6aa3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if column != \"geometry\":\n",
    "        df[column] = df[column].astype(\"int\")\n",
    "\n",
    "\n",
    "df[\"geometry\"] = df.apply(lambda x: wkt.loads(str(x[\"geometry\"])), axis=1)\n",
    "\n",
    "poly_sectors_gdf = geopandas.GeoDataFrame(\n",
    "    df, crs={\"init\": \"epsg:4326\"}, geometry=\"geometry\"\n",
    ")\n",
    "\n",
    "map_1 = keplergl.KeplerGl(height=900)\n",
    "map_1.add_data(\n",
    "    data=poly_sectors_gdf\n",
    ")\n",
    "map_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Geo",
   "language": "python",
   "name": "geo_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
