{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0af62a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T12:03:31.197012Z",
     "iopub.status.busy": "2022-02-21T12:03:31.195922Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from geospark.register import GeoSparkRegistrator\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import FloatType, IntegerType, LongType\n",
    "from pyspark.sql.window import Window\n",
    "from tqdm import tqdm\n",
    "\n",
    "config = yaml.load(open(r\"config/testconfig.yaml\"), Loader=yaml.FullLoader)\n",
    "conf = SparkConf().setAll(config[\"sparkConf\"].items())\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"OSMDistribution\")\n",
    "    .config(conf=conf)\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "GeoSparkRegistrator.registerAll(spark)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from lib.osmFeatures import *\n",
    "from lib.distribution import *\n",
    "from lib.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83996f45",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cd78f06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T13:50:55.498307Z",
     "iopub.status.busy": "2022-02-16T13:50:55.497733Z",
     "iopub.status.idle": "2022-02-16T13:50:55.839861Z",
     "shell.execute_reply": "2022-02-16T13:50:55.837873Z",
     "shell.execute_reply.started": "2022-02-16T13:50:55.498242Z"
    }
   },
   "outputs": [],
   "source": [
    "# Features table and features\n",
    "osmFeatureSpecification = [\n",
    "    \"lowLvlBuild\",\n",
    "    \"middleLvlBuild\",\n",
    "    \"highLvlBuild\",\n",
    "    \"lvlBuild\",\n",
    "    \"allBuild\",\n",
    "    \"adminBuild\",\n",
    "    \"industrialObj\",\n",
    "    \"publicTransportObj\",\n",
    "    \"residentObj\",\n",
    "    \"medsObj\",\n",
    "    \"hotelObj\",\n",
    "    \"entertainObj\",\n",
    "    \"retailObj\",\n",
    "    \"religiousObj\",\n",
    "    \"histObj\",\n",
    "    \"parkObj\",\n",
    "    \"sportObj\",\n",
    "    \"campObj\",\n",
    "    \"beachObj\",\n",
    "    \"foodObj\",\n",
    "    \"militaryObj\",\n",
    "    \"prisonObj\",\n",
    "    \"parkingObj\",\n",
    "    \"roadObj\",\n",
    "]\n",
    "\n",
    "grid = spark.table(config[\"tableConf\"][\"gridBuffers\"])\n",
    "\n",
    "osmGeometry = spark.table(config[\"tableConf\"][\"osmGeometryTableName\"]).filter(\n",
    "    col(\"load_date\") == config[\"tableConf\"][\"osmLoadDate\"]\n",
    ")\n",
    "\n",
    "osmTag = spark.table(config[\"tableConf\"][\"osmTagTableName\"]).filter(\n",
    "    col(\"load_date\") == config[\"tableConf\"][\"osmLoadDate\"]\n",
    ")\n",
    "\n",
    "allOsmObjectsTbl = f\"{dbName}.{prefixName}_all_osm_objects\"\n",
    "osmObjectsTbl = f\"{dbName}.{prefixName}_osm_objects\"\n",
    "osmID = [\"osm_id\", \"osm_type\"]\n",
    "\n",
    "allOsmObjects = getOsmObjects(osmGeometry, osmTag, osmFeatureSpecification)\n",
    "\n",
    "saveTableOverwritePartition(allOsmObjects, 50, osmID, allOsmObjectsTbl)\n",
    "\n",
    "osmObjects = (\n",
    "    spark.table(allOsmObjectsTbl)\n",
    "    .na.drop(how=\"all\", subset=osmFeatureSpecification)\n",
    ")\n",
    "\n",
    "saveTableOverwritePartition(osmObjects, 50, osmID, osmObjectsTbl)\n",
    "\n",
    "featuresTable = f\"{dbName}.{prefixName}_osm_objects\"\n",
    "\n",
    "featuresGeometry = \"osm_geom_wkt\"\n",
    "gridID = \"gid\"\n",
    "gridGeometry = \"geom_wkt\"\n",
    "\n",
    "categoricalFeatures = None\n",
    "\n",
    "# Dictionary tables: which cell buffer intersect which cell\n",
    "buffersDicts = {\n",
    "    \"\": None,\n",
    "    spark.table(f\"{dbName}.{prefixName}_grid_dict_buffer_1km\"): \"buffer_1km\",\n",
    "    spark.table(f\"{dbName}.{prefixName}_grid_dict_buffer_2km\"): \"buffer_2km\",\n",
    "    spark.table(f\"{dbName}.{prefixName}_grid_dict_buffer_3km\"): \"buffer_3km\",\n",
    "    spark.table(f\"{dbName}.{prefixName}_grid_dict_buffer_4km\"): \"buffer_4km\",\n",
    "    spark.table(f\"{dbName}.{prefixName}_grid_dict_buffer_5km\"): \"buffer_5km\",\n",
    "}\n",
    "\n",
    "# Tables for writing and their aliases\n",
    "tblAndAliases = {\n",
    "    f\"{dbName}.{prefixName}_grid_osm_grid\": \"grid\",\n",
    "    f\"{dbName}.{prefixName}_grid_osm_1km\": \"1km\",\n",
    "    f\"{dbName}.{prefixName}_grid_osm_2km\": \"2km\",\n",
    "    f\"{dbName}.{prefixName}_grid_osm_3km\": \"3km\",\n",
    "    f\"{dbName}.{prefixName}_grid_osm_4km\": \"4km\",\n",
    "    f\"{dbName}.{prefixName}_grid_osm_5km\": \"5km\"}\n",
    "\n",
    "toWriteTbls = list(tblAndAliases.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d594d",
   "metadata": {},
   "source": [
    "## Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tblNumber, bufferTbl in enumerate(buffersDicts.keys()):  \n",
    "    print(bufferTbl)\n",
    "    \n",
    "    bufferData = bufferTbl\n",
    "    bufferColumn = buffersDicts[bufferTbl]\n",
    "    \n",
    "    for featureNumber, feature in enumerate(osmFeatureSpecification): \n",
    "        \n",
    "        numericalFeatures = [feature]\n",
    "    \n",
    "        dataFeatures = (\n",
    "            spark.table(featuresTable)\n",
    "            .dropDuplicates([\"osm_id\", \"osm_type\"])\n",
    "            .filter(col(f\"{feature}\") > 0)\n",
    "            .select(col(f\"{feature}\"), col(f\"{featuresGeometry}\"))\n",
    "            )\n",
    "        \n",
    "        gridDistrib = GridDistribution(\n",
    "            grid,\n",
    "            gridID,\n",
    "            gridGeometry,\n",
    "            dataFeatures,\n",
    "            featuresGeometry,\n",
    "            numericalFeatures,\n",
    "            categoricalFeatures,\n",
    "            categoricalFunctions=None,\n",
    "            numericalFunctions=[\"sum\"]\n",
    "        )\n",
    "        \n",
    "        featuresAndGrid = gridDistrib.featuresByGrid()\n",
    "\n",
    "        gridDistribFeatureLocality = gridDistrib.gridFeaturesAgg(\n",
    "            featuresAndGrid, bufferData, bufferColumn\n",
    "        )\n",
    "        \n",
    "        if featureNumber == 0:\n",
    "            gridDistribLocality = gridDistribFeatureLocality\n",
    "        else:\n",
    "            gridDistribLocality = gridDistribLocality.join(gridDistribFeatureLocality, gridID, \"outer\")\n",
    "    \n",
    "        \n",
    "    saveTableOverwritePartition(\n",
    "        gridDistribLocality, 50, [gridID], toWriteTbls[tblNumber]\n",
    "    )\n",
    "\n",
    "toWriteTbl = f\"{dbName}.{prefixName}_geo_grid_osm\"\n",
    "\n",
    "OSMJoining = gridDistrib.joining(tblAndAliases)\n",
    "\n",
    "saveTableOverwritePartition(\n",
    "    OSMJoining,\n",
    "    135,\n",
    "    [gridID],\n",
    "    toWriteTbl,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa433ac",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ee287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import keplergl\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ffc06c",
   "metadata": {},
   "source": [
    "### Take only one region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a63b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "regionID = # insert your value\n",
    "featuresDF = spark.table(f\"{dbName}.{prefixName}_geo_grid_osm\")\n",
    "gridLocal = grid.filter(col(\"region_id\") == regionID)\n",
    "\n",
    "featuresDF = (\n",
    "    featuresDF\n",
    "    .join(gridLocal, [f\"{gridID}\"], \"inner\")\n",
    "    .withColumnRenamed(f\"{gridGeometry}\", \"geometry\")\n",
    ")\n",
    "\n",
    "print(featuresDF.count())\n",
    "\n",
    "df = featuresDF.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076bf50",
   "metadata": {},
   "source": [
    "### Transform to geopandas and add to map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da44eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if column != \"geometry\":\n",
    "        df[column] = df[column].astype(\"int\")\n",
    "\n",
    "\n",
    "df[\"geometry\"] = df.apply(lambda x: wkt.loads(str(x[\"geometry\"])), axis=1)\n",
    "\n",
    "poly_sectors_gdf = geopandas.GeoDataFrame(\n",
    "    df, crs={\"init\": \"epsg:4326\"}, geometry=\"geometry\"\n",
    ")\n",
    "\n",
    "map_1 = keplergl.KeplerGl(height=900)\n",
    "map_1.add_data(\n",
    "    data=poly_sectors_gdf\n",
    ")\n",
    "map_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Geo (Python)",
   "language": "python",
   "name": "geo_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
